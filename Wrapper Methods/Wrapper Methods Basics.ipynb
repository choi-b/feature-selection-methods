{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper Methods\n",
    "\n",
    "* Greedy search algorithms\n",
    "* Utilizes a specific classifier to select the optimal set of features\n",
    "* Sequential feature selection algorithms add or remove one feature at the time based on the classifier performance until a feature subset of the desired size k is reached, or any other desired criteria is met\n",
    "\n",
    "<b>Three Types of Wrapper Methods</b>\n",
    "1. Step Forward Feature Selection - begin from no feature and add one at a time\n",
    "2. Step Backwards Feature Selection - begins from all the features and removes one feature at a time\n",
    "3. Exhaustive Feature Selection - tries all possible feature combinations\n",
    "\n",
    "<b>Wrapper Methods Summary:</b>\n",
    "* Extremely computationally expensive\n",
    "* Often not feasible due to high number of features in real world dataset\n",
    "* Feature space optimized for a specific algorithm\n",
    "* Should provide the highest performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Forward Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to stop the search\n",
    "* Ideal: when performance does NOT increase beyond a threshold. Threshold to be defined by the user\n",
    "* MLXtend implementation: when certain number of features is reached. (Number of features is defined by the user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFS (Sequential Feature Selection) libraries\n",
    "\n",
    "* MLxtend vs.\n",
    "* Scikit-learn (preferred by course instructor)\n",
    "    * slightly faster\n",
    "    * can stop based on model performance\n",
    "    * there are many parameters we already know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Forward Feature Selection (MLXtend example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 109)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the titanic dataset\n",
    "df = pd.read_csv('../precleaned-datasets/dataset_2.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>var_107</th>\n",
       "      <th>var_108</th>\n",
       "      <th>var_109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.532710</td>\n",
       "      <td>3.280834</td>\n",
       "      <td>17.982476</td>\n",
       "      <td>4.404259</td>\n",
       "      <td>2.349910</td>\n",
       "      <td>0.603264</td>\n",
       "      <td>2.784655</td>\n",
       "      <td>0.323146</td>\n",
       "      <td>12.009691</td>\n",
       "      <td>0.139346</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079066</td>\n",
       "      <td>6.748819</td>\n",
       "      <td>2.941445</td>\n",
       "      <td>18.360496</td>\n",
       "      <td>17.726613</td>\n",
       "      <td>7.774031</td>\n",
       "      <td>1.473441</td>\n",
       "      <td>1.973832</td>\n",
       "      <td>0.976806</td>\n",
       "      <td>2.541417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.821374</td>\n",
       "      <td>12.098722</td>\n",
       "      <td>13.309151</td>\n",
       "      <td>4.125599</td>\n",
       "      <td>1.045386</td>\n",
       "      <td>1.832035</td>\n",
       "      <td>1.833494</td>\n",
       "      <td>0.709090</td>\n",
       "      <td>8.652883</td>\n",
       "      <td>0.102757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479789</td>\n",
       "      <td>7.795290</td>\n",
       "      <td>3.557890</td>\n",
       "      <td>17.383378</td>\n",
       "      <td>15.193423</td>\n",
       "      <td>8.263673</td>\n",
       "      <td>1.878108</td>\n",
       "      <td>0.567939</td>\n",
       "      <td>1.018818</td>\n",
       "      <td>1.416433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.938776</td>\n",
       "      <td>7.952752</td>\n",
       "      <td>0.972671</td>\n",
       "      <td>3.459267</td>\n",
       "      <td>1.935782</td>\n",
       "      <td>0.621463</td>\n",
       "      <td>2.338139</td>\n",
       "      <td>0.344948</td>\n",
       "      <td>9.937850</td>\n",
       "      <td>11.691283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.861487</td>\n",
       "      <td>6.130886</td>\n",
       "      <td>3.401064</td>\n",
       "      <td>15.850471</td>\n",
       "      <td>14.620599</td>\n",
       "      <td>6.849776</td>\n",
       "      <td>1.098210</td>\n",
       "      <td>1.959183</td>\n",
       "      <td>1.575493</td>\n",
       "      <td>1.857893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.020690</td>\n",
       "      <td>9.900544</td>\n",
       "      <td>17.869637</td>\n",
       "      <td>4.366715</td>\n",
       "      <td>1.973693</td>\n",
       "      <td>2.026012</td>\n",
       "      <td>2.853025</td>\n",
       "      <td>0.674847</td>\n",
       "      <td>11.816859</td>\n",
       "      <td>0.011151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340944</td>\n",
       "      <td>7.240058</td>\n",
       "      <td>2.417235</td>\n",
       "      <td>15.194609</td>\n",
       "      <td>13.553772</td>\n",
       "      <td>7.229971</td>\n",
       "      <td>0.835158</td>\n",
       "      <td>2.234482</td>\n",
       "      <td>0.946170</td>\n",
       "      <td>2.700606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.909506</td>\n",
       "      <td>10.576516</td>\n",
       "      <td>0.934191</td>\n",
       "      <td>3.419572</td>\n",
       "      <td>1.871438</td>\n",
       "      <td>3.340811</td>\n",
       "      <td>1.868282</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>13.585620</td>\n",
       "      <td>1.153366</td>\n",
       "      <td>...</td>\n",
       "      <td>2.738095</td>\n",
       "      <td>6.565509</td>\n",
       "      <td>4.341414</td>\n",
       "      <td>15.893832</td>\n",
       "      <td>11.929787</td>\n",
       "      <td>6.954033</td>\n",
       "      <td>1.853364</td>\n",
       "      <td>0.511027</td>\n",
       "      <td>2.599562</td>\n",
       "      <td>0.811364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_1      var_2      var_3     var_4     var_5     var_6     var_7  \\\n",
       "0  4.532710   3.280834  17.982476  4.404259  2.349910  0.603264  2.784655   \n",
       "1  5.821374  12.098722  13.309151  4.125599  1.045386  1.832035  1.833494   \n",
       "2  1.938776   7.952752   0.972671  3.459267  1.935782  0.621463  2.338139   \n",
       "3  6.020690   9.900544  17.869637  4.366715  1.973693  2.026012  2.853025   \n",
       "4  3.909506  10.576516   0.934191  3.419572  1.871438  3.340811  1.868282   \n",
       "\n",
       "      var_8      var_9     var_10  ...   var_100   var_101   var_102  \\\n",
       "0  0.323146  12.009691   0.139346  ...  2.079066  6.748819  2.941445   \n",
       "1  0.709090   8.652883   0.102757  ...  2.479789  7.795290  3.557890   \n",
       "2  0.344948   9.937850  11.691283  ...  1.861487  6.130886  3.401064   \n",
       "3  0.674847  11.816859   0.011151  ...  1.340944  7.240058  2.417235   \n",
       "4  0.439865  13.585620   1.153366  ...  2.738095  6.565509  4.341414   \n",
       "\n",
       "     var_103    var_104   var_105   var_106   var_107   var_108   var_109  \n",
       "0  18.360496  17.726613  7.774031  1.473441  1.973832  0.976806  2.541417  \n",
       "1  17.383378  15.193423  8.263673  1.878108  0.567939  1.018818  1.416433  \n",
       "2  15.850471  14.620599  6.849776  1.098210  1.959183  1.575493  1.857893  \n",
       "3  15.194609  13.553772  7.229971  0.835158  2.234482  0.946170  2.700606  \n",
       "4  15.893832  11.929787  6.954033  1.853364  0.511027  2.599562  0.811364  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For faster demonstration purposes, subset this data to include the first 20 columns + 'target'\n",
    "df_sub = df.iloc[:, : 20] #first 20 columns\n",
    "df_sub2 = df[['target']] #target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df_sub, df_sub2], axis=1) #axis=1 to merge across columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_12</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_14</th>\n",
       "      <th>var_15</th>\n",
       "      <th>var_16</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_18</th>\n",
       "      <th>var_19</th>\n",
       "      <th>var_20</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.532710</td>\n",
       "      <td>3.280834</td>\n",
       "      <td>1.798248e+01</td>\n",
       "      <td>4.404259</td>\n",
       "      <td>2.349910</td>\n",
       "      <td>0.603264</td>\n",
       "      <td>2.784655</td>\n",
       "      <td>0.323146</td>\n",
       "      <td>12.009691</td>\n",
       "      <td>0.139346</td>\n",
       "      <td>...</td>\n",
       "      <td>2.808895</td>\n",
       "      <td>1.244055</td>\n",
       "      <td>11.269688</td>\n",
       "      <td>15.866550</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.181500e+00</td>\n",
       "      <td>1.903910</td>\n",
       "      <td>4.667888</td>\n",
       "      <td>1.842749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.821374</td>\n",
       "      <td>12.098722</td>\n",
       "      <td>1.330915e+01</td>\n",
       "      <td>4.125599</td>\n",
       "      <td>1.045386</td>\n",
       "      <td>1.832035</td>\n",
       "      <td>1.833494</td>\n",
       "      <td>0.709090</td>\n",
       "      <td>8.652883</td>\n",
       "      <td>0.102757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.001220</td>\n",
       "      <td>8.081647</td>\n",
       "      <td>3.933986</td>\n",
       "      <td>14.350374</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.244384e+01</td>\n",
       "      <td>1.575456</td>\n",
       "      <td>5.275010</td>\n",
       "      <td>2.750981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.938776</td>\n",
       "      <td>7.952752</td>\n",
       "      <td>9.726712e-01</td>\n",
       "      <td>3.459267</td>\n",
       "      <td>1.935782</td>\n",
       "      <td>0.621463</td>\n",
       "      <td>2.338139</td>\n",
       "      <td>0.344948</td>\n",
       "      <td>9.937850</td>\n",
       "      <td>11.691283</td>\n",
       "      <td>...</td>\n",
       "      <td>3.239122</td>\n",
       "      <td>2.699376</td>\n",
       "      <td>10.030416</td>\n",
       "      <td>14.977220</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.636780e-07</td>\n",
       "      <td>2.605838</td>\n",
       "      <td>5.459521</td>\n",
       "      <td>3.437779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.020690</td>\n",
       "      <td>9.900544</td>\n",
       "      <td>1.786964e+01</td>\n",
       "      <td>4.366715</td>\n",
       "      <td>1.973693</td>\n",
       "      <td>2.026012</td>\n",
       "      <td>2.853025</td>\n",
       "      <td>0.674847</td>\n",
       "      <td>11.816859</td>\n",
       "      <td>0.011151</td>\n",
       "      <td>...</td>\n",
       "      <td>2.760518</td>\n",
       "      <td>4.067190</td>\n",
       "      <td>14.040960</td>\n",
       "      <td>15.363394</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.278596e+00</td>\n",
       "      <td>2.447368</td>\n",
       "      <td>4.622004</td>\n",
       "      <td>3.166859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.909506</td>\n",
       "      <td>10.576516</td>\n",
       "      <td>9.341910e-01</td>\n",
       "      <td>3.419572</td>\n",
       "      <td>1.871438</td>\n",
       "      <td>3.340811</td>\n",
       "      <td>1.868282</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>13.585620</td>\n",
       "      <td>1.153366</td>\n",
       "      <td>...</td>\n",
       "      <td>1.682118</td>\n",
       "      <td>9.553305</td>\n",
       "      <td>10.341188</td>\n",
       "      <td>9.436362</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.548740e+01</td>\n",
       "      <td>1.888375</td>\n",
       "      <td>5.975678</td>\n",
       "      <td>1.775326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>5.392593</td>\n",
       "      <td>1.336383</td>\n",
       "      <td>8.212083e+00</td>\n",
       "      <td>2.966147</td>\n",
       "      <td>2.387417</td>\n",
       "      <td>3.019191</td>\n",
       "      <td>2.289753</td>\n",
       "      <td>0.696969</td>\n",
       "      <td>9.218114</td>\n",
       "      <td>0.451762</td>\n",
       "      <td>...</td>\n",
       "      <td>3.859533</td>\n",
       "      <td>1.418175</td>\n",
       "      <td>11.611067</td>\n",
       "      <td>14.421331</td>\n",
       "      <td>0.92</td>\n",
       "      <td>9.871287e-01</td>\n",
       "      <td>2.095555</td>\n",
       "      <td>4.926871</td>\n",
       "      <td>2.124513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>3.544616</td>\n",
       "      <td>5.376492</td>\n",
       "      <td>-5.253303e-07</td>\n",
       "      <td>3.469798</td>\n",
       "      <td>3.473573</td>\n",
       "      <td>4.555753</td>\n",
       "      <td>1.238703</td>\n",
       "      <td>0.332744</td>\n",
       "      <td>15.448531</td>\n",
       "      <td>4.587770</td>\n",
       "      <td>...</td>\n",
       "      <td>1.440717</td>\n",
       "      <td>6.600696</td>\n",
       "      <td>14.768869</td>\n",
       "      <td>14.803225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.120715e+01</td>\n",
       "      <td>1.392348</td>\n",
       "      <td>4.437067</td>\n",
       "      <td>1.539597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>4.266667</td>\n",
       "      <td>7.618359</td>\n",
       "      <td>1.728767e+01</td>\n",
       "      <td>3.241785</td>\n",
       "      <td>1.264538</td>\n",
       "      <td>2.392204</td>\n",
       "      <td>2.181862</td>\n",
       "      <td>0.703589</td>\n",
       "      <td>13.643899</td>\n",
       "      <td>1.555709</td>\n",
       "      <td>...</td>\n",
       "      <td>2.341123</td>\n",
       "      <td>2.649408</td>\n",
       "      <td>10.825765</td>\n",
       "      <td>14.916928</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.629104e-02</td>\n",
       "      <td>2.145410</td>\n",
       "      <td>4.985115</td>\n",
       "      <td>2.254736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>5.130579</td>\n",
       "      <td>6.749948</td>\n",
       "      <td>1.060437e+01</td>\n",
       "      <td>3.578128</td>\n",
       "      <td>2.770539</td>\n",
       "      <td>2.089231</td>\n",
       "      <td>2.698422</td>\n",
       "      <td>1.165991</td>\n",
       "      <td>11.427852</td>\n",
       "      <td>0.020571</td>\n",
       "      <td>...</td>\n",
       "      <td>3.696110</td>\n",
       "      <td>4.120188</td>\n",
       "      <td>10.762168</td>\n",
       "      <td>13.865338</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.704309e+00</td>\n",
       "      <td>3.280301</td>\n",
       "      <td>5.414975</td>\n",
       "      <td>2.503469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>4.537930</td>\n",
       "      <td>6.384039</td>\n",
       "      <td>1.694724e+01</td>\n",
       "      <td>4.297897</td>\n",
       "      <td>2.109488</td>\n",
       "      <td>1.058434</td>\n",
       "      <td>2.442638</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>11.458514</td>\n",
       "      <td>0.044563</td>\n",
       "      <td>...</td>\n",
       "      <td>2.867539</td>\n",
       "      <td>1.693693</td>\n",
       "      <td>9.477326</td>\n",
       "      <td>16.254239</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.934736e-01</td>\n",
       "      <td>2.017655</td>\n",
       "      <td>4.154889</td>\n",
       "      <td>2.646958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_1      var_2         var_3     var_4     var_5     var_6  \\\n",
       "0      4.532710   3.280834  1.798248e+01  4.404259  2.349910  0.603264   \n",
       "1      5.821374  12.098722  1.330915e+01  4.125599  1.045386  1.832035   \n",
       "2      1.938776   7.952752  9.726712e-01  3.459267  1.935782  0.621463   \n",
       "3      6.020690   9.900544  1.786964e+01  4.366715  1.973693  2.026012   \n",
       "4      3.909506  10.576516  9.341910e-01  3.419572  1.871438  3.340811   \n",
       "...         ...        ...           ...       ...       ...       ...   \n",
       "49995  5.392593   1.336383  8.212083e+00  2.966147  2.387417  3.019191   \n",
       "49996  3.544616   5.376492 -5.253303e-07  3.469798  3.473573  4.555753   \n",
       "49997  4.266667   7.618359  1.728767e+01  3.241785  1.264538  2.392204   \n",
       "49998  5.130579   6.749948  1.060437e+01  3.578128  2.770539  2.089231   \n",
       "49999  4.537930   6.384039  1.694724e+01  4.297897  2.109488  1.058434   \n",
       "\n",
       "          var_7     var_8      var_9     var_10  ...    var_12    var_13  \\\n",
       "0      2.784655  0.323146  12.009691   0.139346  ...  2.808895  1.244055   \n",
       "1      1.833494  0.709090   8.652883   0.102757  ...  2.001220  8.081647   \n",
       "2      2.338139  0.344948   9.937850  11.691283  ...  3.239122  2.699376   \n",
       "3      2.853025  0.674847  11.816859   0.011151  ...  2.760518  4.067190   \n",
       "4      1.868282  0.439865  13.585620   1.153366  ...  1.682118  9.553305   \n",
       "...         ...       ...        ...        ...  ...       ...       ...   \n",
       "49995  2.289753  0.696969   9.218114   0.451762  ...  3.859533  1.418175   \n",
       "49996  1.238703  0.332744  15.448531   4.587770  ...  1.440717  6.600696   \n",
       "49997  2.181862  0.703589  13.643899   1.555709  ...  2.341123  2.649408   \n",
       "49998  2.698422  1.165991  11.427852   0.020571  ...  3.696110  4.120188   \n",
       "49999  2.442638  0.419355  11.458514   0.044563  ...  2.867539  1.693693   \n",
       "\n",
       "          var_14     var_15  var_16        var_17    var_18    var_19  \\\n",
       "0      11.269688  15.866550    0.00  1.181500e+00  1.903910  4.667888   \n",
       "1       3.933986  14.350374    0.00  1.244384e+01  1.575456  5.275010   \n",
       "2      10.030416  14.977220    0.00  7.636780e-07  2.605838  5.459521   \n",
       "3      14.040960  15.363394    0.94  1.278596e+00  2.447368  4.622004   \n",
       "4      10.341188   9.436362    0.00  1.548740e+01  1.888375  5.975678   \n",
       "...          ...        ...     ...           ...       ...       ...   \n",
       "49995  11.611067  14.421331    0.92  9.871287e-01  2.095555  4.926871   \n",
       "49996  14.768869  14.803225    0.00  1.120715e+01  1.392348  4.437067   \n",
       "49997  10.825765  14.916928    0.93  1.629104e-02  2.145410  4.985115   \n",
       "49998  10.762168  13.865338    0.00  3.704309e+00  3.280301  5.414975   \n",
       "49999   9.477326  16.254239    0.00  6.934736e-01  2.017655  4.154889   \n",
       "\n",
       "         var_20  target  \n",
       "0      1.842749       1  \n",
       "1      2.750981       0  \n",
       "2      3.437779       0  \n",
       "3      3.166859       1  \n",
       "4      1.775326       1  \n",
       "...         ...     ...  \n",
       "49995  2.124513       1  \n",
       "49996  1.539597       1  \n",
       "49997  2.254736       1  \n",
       "49998  2.503469       1  \n",
       "49999  2.646958       1  \n",
       "\n",
       "[50000 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 20), (15000, 20))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df2.drop(labels=['target'], axis=1),\n",
    "    df2['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicate I want to select 10 features from the total\n",
    "sfs1 = SFS(RandomForestClassifier(n_jobs=1), #n_jobs = how many processors your computer has\n",
    "          k_features=10,\n",
    "          forward=True,\n",
    "          floating=False,\n",
    "          verbose=2,\n",
    "          scoring='roc_auc',\n",
    "          cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.9s remaining:    0.0s\n",
      "\n",
      "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
     ]
    }
   ],
   "source": [
    "sfs1 = sfs1.fit(np.array(X_train.fillna(0)), y_train)\n",
    "#you are supposed to be able to see that after adding the Xth feature, the score will begin to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Backward Feature Selection\n",
    "* Example: Say model has n=4 features\n",
    "* Remove 1 feature (All possible models with 3 (n-1) features)\n",
    "* All possible models with 2 features\n",
    "* Continue until performance does not decrease beyond a threshold (defined by user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicate I want to select 10 features from the total\n",
    "\n",
    "#forward = False\n",
    "sfs2 = SFS(RandomForestClassifier(n_jobs=1),\n",
    "          k_features=10,\n",
    "          forward=False,\n",
    "          floating=False,\n",
    "          verbose=2,\n",
    "          scoring='roc_auc',\n",
    "          cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.3s remaining:    0.0s\n",
      "\n",
      "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
     ]
    }
   ],
   "source": [
    "sfs2 = sfs2.fit(np.array(X_train.fillna(0)), y_train) #similar to above method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exhaustive Search Feature Selection\n",
    "* Example: Say model has n=4 features\n",
    "* Will find all possible combinations of 4, 3, 2, and 1 feature models\n",
    "* Build ML algorithm for all of those combinations\n",
    "* Takes the most computing resource, often impractical\n",
    "* To improve performance, you can define the min and max # of features of the subsets to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs1 = EFS(RandomForestClassifier(n_jobs=1, random_state=0),\n",
    "          min_features=1,\n",
    "          max_features=4,\n",
    "          scoring='roc_auc',\n",
    "          print_progress=True,\n",
    "          cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs1 = efs1.fit(np.array(X_train[X_train.columns[0:4]].fillna(0)), y_train) \n",
    "#won't be running this since EFS is computationally expensive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
